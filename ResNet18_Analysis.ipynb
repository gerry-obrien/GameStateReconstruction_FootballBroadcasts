{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d17eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - C:\\Users\\gerry\\OneDrive\\ESSEC-CS\\M2\\Foundations_Deep_Learning\\Project\\yolo_run_20260122_2200\\resnet18\\analysis\\resnet_classification_report.txt\n",
      " - C:\\Users\\gerry\\OneDrive\\ESSEC-CS\\M2\\Foundations_Deep_Learning\\Project\\yolo_run_20260122_2200\\resnet18\\analysis\\resnet_confusion_matrix.png\n",
      " - C:\\Users\\gerry\\OneDrive\\ESSEC-CS\\M2\\Foundations_Deep_Learning\\Project\\yolo_run_20260122_2200\\resnet18\\analysis\\resnet_confusion_matrix_normalized.png\n",
      " - C:\\Users\\gerry\\OneDrive\\ESSEC-CS\\M2\\Foundations_Deep_Learning\\Project\\yolo_run_20260122_2200\\resnet18\\analysis\\resnet_metrics_derived.json\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RUN_DIR = Path(r\"C:\\Users\\gerry\\OneDrive\\ESSEC-CS\\M2\\Foundations_Deep_Learning\\Project\\yolo_run_20260122_2200\")\n",
    "RESNET_DIR = RUN_DIR / \"resnet18\"\n",
    "METRICS_JSON = RESNET_DIR / \"resnet18_metrics.json\"\n",
    "META_JSON    = RESNET_DIR / \"resnet18_meta.json\"\n",
    "OUT_DIR      = RESNET_DIR / \"analysis\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def safe_div(a, b):\n",
    "    return a / b if b != 0 else 0.0\n",
    "\n",
    "def compute_metrics_from_cm(cm: np.ndarray, class_names):\n",
    "    # cm rows=true, cols=pred\n",
    "    supports = cm.sum(axis=1)\n",
    "    pred_totals = cm.sum(axis=0)\n",
    "    total = cm.sum()\n",
    "\n",
    "    acc = safe_div(np.trace(cm), total)\n",
    "    recalls = np.array([safe_div(cm[i, i], supports[i]) for i in range(len(class_names))])\n",
    "    precisions = np.array([safe_div(cm[i, i], pred_totals[i]) for i in range(len(class_names))])\n",
    "    f1s = np.array([\n",
    "        safe_div(2 * precisions[i] * recalls[i], precisions[i] + recalls[i])\n",
    "        for i in range(len(class_names))\n",
    "    ])\n",
    "\n",
    "    bal_acc = float(recalls.mean())\n",
    "    macro_f1 = float(f1s.mean())\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": float(acc),\n",
    "        \"balanced_accuracy\": float(bal_acc),\n",
    "        \"macro_f1\": macro_f1,\n",
    "        \"per_class\": {\n",
    "            class_names[i]: {\n",
    "                \"precision\": float(precisions[i]),\n",
    "                \"recall\": float(recalls[i]),\n",
    "                \"f1\": float(f1s[i]),\n",
    "                \"support\": int(supports[i]),\n",
    "            }\n",
    "            for i in range(len(class_names))\n",
    "        },\n",
    "        \"predicted_distribution\": {\n",
    "            class_names[i]: int(pred_totals[i]) for i in range(len(class_names))\n",
    "        },\n",
    "        \"total\": int(total),\n",
    "    }\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, out_path, normalize=False, title=None):\n",
    "    cm_plot = cm.astype(float)\n",
    "    if normalize:\n",
    "        row_sums = cm_plot.sum(axis=1, keepdims=True)\n",
    "        cm_plot = np.divide(cm_plot, row_sums, out=np.zeros_like(cm_plot), where=row_sums != 0)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(5.5, 4.5))\n",
    "    im = ax.imshow(cm_plot)\n",
    "\n",
    "    ax.set_xticks(range(len(class_names)))\n",
    "    ax.set_yticks(range(len(class_names)))\n",
    "    ax.set_xticklabels(class_names, rotation=45, ha=\"right\")\n",
    "    ax.set_yticklabels(class_names)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_title(title or (\"Confusion Matrix\" + (\" (Normalized)\" if normalize else \"\")))\n",
    "\n",
    "    # annotate cells\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            if normalize:\n",
    "                txt = f\"{cm_plot[i, j]:.2f}\"\n",
    "            else:\n",
    "                txt = str(int(cm[i, j]))\n",
    "            ax.text(j, i, txt, ha=\"center\", va=\"center\")\n",
    "\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_path, dpi=200)\n",
    "    plt.close(fig)\n",
    "\n",
    "def main():\n",
    "    metrics = json.loads(METRICS_JSON.read_text(encoding=\"utf-8\"))\n",
    "    meta = json.loads(META_JSON.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "    class_names = metrics.get(\"classes_in_folder_order\", [\"left\", \"right\"])\n",
    "    cm = np.array(metrics[\"confusion_matrix_rows_true_cols_pred\"], dtype=int)\n",
    "\n",
    "    summary = compute_metrics_from_cm(cm, class_names)\n",
    "\n",
    "    # Save text report\n",
    "    report_lines = []\n",
    "    report_lines.append(f\"Best val acc: {metrics['best_val_acc']:.6f}\")\n",
    "    report_lines.append(f\"Best phase: {metrics['best_phase']}, epoch in phase: {metrics['best_epoch_in_phase']}\")\n",
    "    report_lines.append(f\"Accuracy: {summary['accuracy']:.6f}\")\n",
    "    report_lines.append(f\"Balanced accuracy: {summary['balanced_accuracy']:.6f}\")\n",
    "    report_lines.append(f\"Macro F1: {summary['macro_f1']:.6f}\")\n",
    "    report_lines.append(\"\")\n",
    "    report_lines.append(\"Per-class metrics:\")\n",
    "    for cls in class_names:\n",
    "        m = summary[\"per_class\"][cls]\n",
    "        report_lines.append(\n",
    "            f\"  {cls:>5s} | P={m['precision']:.3f}  R={m['recall']:.3f}  F1={m['f1']:.3f}  support={m['support']}\"\n",
    "        )\n",
    "    report_lines.append(\"\")\n",
    "    report_lines.append(\"Predicted distribution:\")\n",
    "    for cls in class_names:\n",
    "        report_lines.append(f\"  pred_{cls}: {summary['predicted_distribution'][cls]}\")\n",
    "\n",
    "    (OUT_DIR / \"resnet_classification_report.txt\").write_text(\"\\n\".join(report_lines), encoding=\"utf-8\")\n",
    "\n",
    "    # Save plots\n",
    "    plot_confusion_matrix(\n",
    "        cm, class_names,\n",
    "        OUT_DIR / \"resnet_confusion_matrix.png\",\n",
    "        normalize=False,\n",
    "        title=\"ResNet18 Team Confusion Matrix (Counts)\"\n",
    "    )\n",
    "    plot_confusion_matrix(\n",
    "        cm, class_names,\n",
    "        OUT_DIR / \"resnet_confusion_matrix_normalized.png\",\n",
    "        normalize=True,\n",
    "        title=\"ResNet18 Team Confusion Matrix (Row-normalized)\"\n",
    "    )\n",
    "\n",
    "    # Also save a JSON summary for easy use in LaTeX/table generation\n",
    "    (OUT_DIR / \"resnet_metrics_derived.json\").write_text(json.dumps(summary, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    print(\"Saved:\")\n",
    "    print(\" -\", OUT_DIR / \"resnet_classification_report.txt\")\n",
    "    print(\" -\", OUT_DIR / \"resnet_confusion_matrix.png\")\n",
    "    print(\" -\", OUT_DIR / \"resnet_confusion_matrix_normalized.png\")\n",
    "    print(\" -\", OUT_DIR / \"resnet_metrics_derived.json\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c261cc7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
